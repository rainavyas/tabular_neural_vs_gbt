{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Data\n"
     ]
    }
   ],
   "source": [
    "# Load in data\n",
    "\n",
    "in_dir = '../../data_old'\n",
    "\n",
    "df_train = pd.read_csv(f'{in_dir}/train.csv')\n",
    "df_train_xclim = pd.read_csv(f'{in_dir}/train_xclim.csv')\n",
    "df_dev_in = pd.read_csv(f'{in_dir}/dev_in.csv')\n",
    "df_dev_xclim = pd.read_csv(f'{in_dir}/dev_xclim.csv')\n",
    "df_dev_out = pd.read_csv(f'{in_dir}/dev_out.csv')\n",
    "df_eval_in = pd.read_csv(f'{in_dir}/eval_in.csv')\n",
    "df_eval_out = pd.read_csv(f'{in_dir}/eval_out.csv')\n",
    "print(\"Loaded Data\")\n",
    "\n",
    "df_train_cat = pd.concat([df_train, df_train_xclim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the categorical features\n",
    "cat_features = []\n",
    "for col in df_train_cat:\n",
    "    values = df_train_cat[col].tolist()\n",
    "    unique = list(dict.fromkeys(values))\n",
    "    if len(unique) < 20:\n",
    "        cat_features.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scipy\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "nan_replacements = {}\n",
    "for col in df_train_cat:\n",
    "    if col in cat_features:\n",
    "        nan_replacements[col] = stats.mode(np.asarray(df_train_cat[col].tolist()))[0][0]\n",
    "    else:\n",
    "        nan_replacements[col] = np.mean(np.asarray(df_train_cat[col].dropna().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replaces all NaNs\n",
    "for col in df_train_cat:\n",
    "    df_train[col] = df_train[col].fillna(nan_replacements[col])\n",
    "    df_train_xclim[col] = df_train_xclim[col].fillna(nan_replacements[col])\n",
    "    df_dev_in[col] = df_dev_in[col].fillna(nan_replacements[col])\n",
    "    df_dev_xclim[col] = df_dev_xclim[col].fillna(nan_replacements[col])\n",
    "    df_dev_out[col] = df_dev_out[col].fillna(nan_replacements[col])\n",
    "    df_eval_in[col] = df_eval_in[col].fillna(nan_replacements[col])\n",
    "    df_eval_out[col] = df_eval_out[col].fillna(nan_replacements[col])\n",
    "df_train_cat = pd.concat([df_train, df_train_xclim])\n",
    "print(\"Replaced NaNs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn\n",
    "\n",
    "from typing import Dict\n",
    "\n",
    "import numpy as np\n",
    "import sklearn.preprocessing\n",
    "\n",
    "\n",
    "def normalize(\n",
    "    X: Dict[str, np.ndarray], normalization: str, seed: int, noise: float = 1e-3\n",
    ") -> Dict[str, np.ndarray]:\n",
    "    X_train = X['train_cat']\n",
    "    if normalization == 'standard':\n",
    "        normalizer = sklearn.preprocessing.StandardScaler()\n",
    "    elif normalization == 'quantile':\n",
    "        normalizer = sklearn.preprocessing.QuantileTransformer(\n",
    "            output_distribution='normal',\n",
    "            n_quantiles=max(min(X['train_cat'].shape[0] // 30, 1000), 10),\n",
    "            subsample=1e9,\n",
    "            random_state=seed,\n",
    "        )\n",
    "        if noise:\n",
    "            X_train = X_train.copy()\n",
    "            stds = np.std(X_train, axis=0, keepdims=True)\n",
    "            noise_std = noise / np.maximum(stds, noise)\n",
    "            X_train += noise_std * np.random.default_rng(seed).standard_normal(\n",
    "                X_train.shape\n",
    "            )\n",
    "    else:\n",
    "        raise ValueError(f'unknown normalization: {normalization}')\n",
    "    normalizer.fit(X_train)\n",
    "    return {k: normalizer.transform(v) for k, v in X.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Seed\n",
    "seed = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize using training stats\n",
    "# Quantile normalisation is used (maps to a normal distribution)\n",
    "X_train_cat_np = np.asarray(df_train_cat.iloc[:,6:])\n",
    "X_train_np = np.asarray(df_train.iloc[:,6:])\n",
    "X_train_xclim_np = np.asarray(df_train_xclim.iloc[:,6:])\n",
    "X_dev_in_np = np.asarray(df_dev_in.iloc[:,6:])\n",
    "X_dev_xclim_np = np.asarray(df_dev_xclim.iloc[:,6:])\n",
    "X_dev_out_np = np.asarray(df_dev_out.iloc[:,6:])\n",
    "X_eval_in_np = np.asarray(df_eval_in.iloc[:,6:])\n",
    "X_eval_out_np = np.asarray(df_eval_out.iloc[:,6:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = {'train_cat': X_train_cat_np, 'train': X_train_np, 'train_xclim': X_train_xclim_np, 'dev_in': X_dev_in_np, 'dev_xclim': X_dev_xclim_np, 'dev_out': X_dev_out_np, 'eval_in': X_eval_in_np, 'eval_out': X_eval_out_np}\n",
    "X = normalize(X, normalization='quantile', seed=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[:,6:] = X['train']\n",
    "df_train_xclim.loc[:,6:] = X['train_xclim']\n",
    "df_dev_in.loc[:,6:] = X['dev_in']\n",
    "df_dev_xclim.loc[:,6:] = X['dev_xclim']\n",
    "df_dev_out.loc[:,6:] = X['dev_out']\n",
    "df_eval_in.loc[:,6:] = X['eval_in']\n",
    "df_eval_out.loc[:,6:] = X['eval_out']\n",
    "\n",
    "print('Normalized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save modified dataframes\n",
    "out_dir = '../data_preprocessed_xclim'\n",
    "df_train.to_csv(f'{args.out_dir}/train.csv', index=False)\n",
    "df_train_xclim.to_csv(f'{args.out_dir}/train_xclim.csv', index=False)\n",
    "df_dev_in.to_csv(f'{args.out_dir}/dev_in.csv', index=False)\n",
    "df_dev_xclim.to_csv(f'{args.out_dir}/dev_xclim.csv', index=False)\n",
    "df_dev_out.to_csv(f'{args.out_dir}/dev_out.csv', index=False)\n",
    "df_eval_in.to_csv(f'{args.out_dir}/eval_in.csv', index=False)\n",
    "df_eval_out.to_csv(f'{args.out_dir}/eval_out.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
